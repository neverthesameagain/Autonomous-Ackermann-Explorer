# Quick Reference Guide
## Autonomous Exploration System

---

## ğŸš€ Quick Start

```bash
cd /Users/aryanmathur/Desktop/RDCP/take2
source venv/bin/activate
python3 -m src.goal_directed_explorer
```

---

## ğŸ¯ What You'll See

### Console Output

```
ğŸ” INITIAL ENVIRONMENT SCAN
ğŸ“ INITIAL FRONTIERS DETECTED: 69

ğŸ” EVALUATING 69 FRONTIERS:
Top 5 Frontier Candidates:
ğŸ‘‰ 1. (3.55, 7.25) - Score: 26.03  â† BEST (highest score)
      Progress to goal: 4.62m       â† Moves 4.62m closer to goal
      Dist to frontier: 5.47m       â† 5.47m away from robot
      Dist to goal: 18.01m          â† 18.01m from goal
      Info gain: 914 cells          â† Will explore 914 unknown cells

ğŸ¯ SELECTED BEST FRONTIER: (3.55, 7.25)

âœ… FRONTIER #1 REACHED!
ğŸ” SCANNING FROM NEW POSITION...
ğŸ“ NEW FRONTIERS DETECTED: 47
... (repeats until goal reached)

ğŸ¯ FINAL GOAL REACHED!
```

### 2D Visualization (Left)

| Symbol | Meaning |
|--------|---------|
| ğŸŸ¢ Green Circle | START position |
| âŒ Red X | GOAL position |
| ğŸ”µ Blue Circle | Current robot |
| â­ Yellow Star | Current target frontier |
| ğŸŸ¢ Numbered Circles | Visited frontiers (1, 2, 3...) |
| ğŸ”µ Blue Line | Path traveled |
| ğŸŸ¢ Dashed Line | Planned path |
| ğŸ”µ Light Blue | Explored free space |
| ğŸ”´ Dark Red | Detected obstacles |
| âšª Gray | Unknown areas |

### 3D Visualization (Right)

- Obstacles as 3D shapes
- Robot as blue sphere
- Trajectory as blue line

---

## âš™ï¸ Customization

### Change Start/Goal

Edit `src/goal_directed_explorer.py` line 670:

```python
def main():
    START = (5.0, 3.0)   # Your start (x, y)
    GOAL = (15.0, 17.0)  # Your goal (x, y)
```

### Adjust Speed

Line 60-64:

```python
velocity_controller = TrapezoidalVelocityController(
    max_velocity=0.8,      # Increase for faster (default: 0.5)
    max_acceleration=0.5   # Increase for quicker (default: 0.3)
)
```

### Change Safety Margin

Line 203, 367:

```python
inflation_radius=5  # Larger = more cautious (default: 3)
```

---

## ğŸ” Understanding the Algorithm

### Frontier Selection Score

```
score = (progress_to_goal Ã— 5.0 + info_gain Ã— 0.05) / (1.0 + distance Ã— 0.3)
```

**Higher score = Better frontier**

- **Progress to goal** (Ã—5.0): Most important - how much closer to goal
- **Info gain** (Ã—0.05): Bonus for exploring more unknown cells
- **Distance** (Ã—0.3): Penalty for far frontiers

### Example

```
Frontier A: Progress=4.62m, Distance=5.47m, Info=914
Score = (4.62Ã—5.0 + 914Ã—0.05) / (1.0 + 5.47Ã—0.3)
      = (23.1 + 45.7) / 2.64
      = 26.03  â† BEST!

Frontier B: Progress=2.15m, Distance=3.21m, Info=650
Score = (2.15Ã—5.0 + 650Ã—0.05) / (1.0 + 3.21Ã—0.3)
      = (10.75 + 32.5) / 1.96
      = 22.09  â† Lower score
```

---

## ğŸ“Š Key Metrics

| Metric | Typical Value |
|--------|---------------|
| Frontiers visited | 3-8 |
| Distance traveled | 20-30m |
| Time to goal | 60-120s |
| Map explored | 70-90% |
| Average speed | 0.25-0.35 m/s |

---

## ğŸ› Troubleshooting

### Robot goes to wrong frontier
âœ… **FIXED!** Now uses Hybrid A* scoring (progressÃ—5.0)

### Too many frontiers shown
âœ… **FIXED!** Only shows current target + visited history

### Robot gets stuck
- Reduce `inflation_radius` from 3 to 2
- Increase `max_velocity` from 0.5 to 0.7

### No path found
- Check if goal is in obstacle
- Reduce `inflation_radius`
- Increase grid `resolution`

---

## ğŸ“ File Structure

```
src/
â”œâ”€â”€ goal_directed_explorer.py  â† MAIN FILE (run this)
â”œâ”€â”€ robot/ackermann.py         â† Robot kinematics
â”œâ”€â”€ sensors/lidar.py            â† LiDAR sensor
â”œâ”€â”€ map/occupancy_grid.py       â† Mapping
â”œâ”€â”€ planning/
â”‚   â”œâ”€â”€ astar.py                â† Path planning
â”‚   â””â”€â”€ frontier_explorer.py    â† Frontier detection
â””â”€â”€ control/
    â””â”€â”€ velocity_controller.py  â† Motion control
```

---

## ğŸ“ What It Does

1. **Start** at (2, 2)
2. **Scan** environment with LiDAR
3. **Detect** all frontiers (boundaries of unknown space)
4. **Evaluate** each frontier with scoring function
5. **Select** best frontier (highest score = most progress to goal)
6. **Plan** path using A*
7. **Navigate** to frontier with smooth motion
8. **Reach** frontier â†’ Clear old frontiers
9. **Repeat** steps 2-8 until goal reached
10. **Success!** ğŸ¯

---

## ğŸ“ˆ Performance Tips

### Faster Exploration
```python
max_velocity=0.8
max_acceleration=0.5
resolution=0.15  # Coarser grid
```

### More Accurate
```python
max_velocity=0.3
resolution=0.05  # Finer grid
inflation_radius=4  # More cautious
```

### Balanced (Default)
```python
max_velocity=0.5
resolution=0.1
inflation_radius=3
```

---

## ğŸ¯ Success Criteria

âœ… Goal reached  
âœ… No collisions  
âœ… Smooth motion  
âœ… Efficient path  
âœ… Good exploration coverage  

---

## ğŸ“ Need Help?

1. Check `COMPLETE_DOCUMENTATION.md` for details
2. Check `FINAL_DOCUMENTATION.md` for algorithms
3. Check console output for errors
4. Verify virtual environment is activated

---

**Status: FULLY FUNCTIONAL** âœ…

*Last Updated: November 10, 2025*
